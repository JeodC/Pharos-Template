name: Release Ports
on:
  schedule:
    - cron: '0 */12 * * *'
  workflow_dispatch:
    inputs:
      force:
        description: 'Force update all ports'
        required: true
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'
  push:
    paths:
      - 'ports/released/**'
  workflow_run:
    workflows: ["Update HM64 Port"]
    types:
      - completed

concurrency:
  group: release-ports
  cancel-in-progress: true

jobs:
  build-and-release:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    if: |
      github.event_name != 'workflow_run' || 
      github.event.workflow_run.conclusion == 'success'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install dependencies
        run: sudo apt-get update && sudo apt-get install -y zip jq gh

      - name: Prepare environment
        run: |
          mkdir -p "$GITHUB_WORKSPACE/temp_ports"
          [ -f "$GITHUB_WORKSPACE/docs/ports.json" ] || echo "[]" > "$GITHUB_WORKSPACE/docs/ports.json"

      # ────────────────────── DETERMINE PORTS ──────────────────────
      - name: Determine ports to process
        id: ports
        run: |
          set -euo pipefail

          PORT_DIRS=()

          if [ "${{ github.event.inputs.force }}" = "true" ]; then
            echo "Force mode: scanning all port.json"
            while IFS= read -r json; do
              PORT_DIRS+=("$(dirname "$json")")
            done < <(find ports/released -type f -name 'port.json' -not -path '*/\.*' | sort -u)
          else
            mapfile -t CHANGED < <(git diff --name-only HEAD^ HEAD)
            for file in "${CHANGED[@]}"; do
              [[ "$file" == ports/released/* ]] || continue

              filepath="$GITHUB_WORKSPACE/$file"
              candidate=""

              # Walk up directories to find port.json
              dir="$(dirname "$filepath")"
              while [[ "$dir" != "$GITHUB_WORKSPACE" ]]; do
                if [[ -f "$dir/port.json" ]]; then
                  candidate="$dir"
                  break
                fi
                dir="$(dirname "$dir")"
              done

              # Special case: .sh file outside port folder
              if [[ -z "$candidate" && "$file" == *.sh ]]; then
                parent="$(dirname "$filepath")"
                for sibling in "$parent"/*/; do
                  [[ -f "$sibling/port.json" ]] && candidate="$sibling" && break
                done
              fi

              [[ -n "$candidate" ]] && PORT_DIRS+=("$candidate")
            done

            # Remove duplicates
            mapfile -t PORT_DIRS < <(printf '%s\n' "${PORT_DIRS[@]}" | sort -u)
          fi

          echo "Found ${#PORT_DIRS[@]} port(s)"
          {
            echo "ports<<EOF"
            printf '%s\n' "${PORT_DIRS[@]}"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      # ────────────────────── PROCESS PORTS ──────────────────────
      - name: Process ports
        if: ${{ steps.ports.outputs.ports != '' }}
        run: |
          set -euo pipefail
          mapfile -t PORT_DIRS < <(echo "${{ steps.ports.outputs.ports }}")
          ZIP_DIR="$GITHUB_WORKSPACE/temp_ports"
          PORTS_JSON="$GITHUB_WORKSPACE/docs/ports.json"

          for PORT_DIR in "${PORT_DIRS[@]}"; do
            PORT_JSON="$PORT_DIR/port.json"
            STAGING_DIR="$(dirname "$PORT_DIR")"
            STAGING_NAME="$(basename "$STAGING_DIR")"

            echo "Processing port in: $PORT_DIR"
            echo "  Staging dir: $STAGING_DIR → will be zipped as ${STAGING_NAME}.zip"

            [[ -f "$PORT_JSON" ]] || { echo "port.json missing"; continue; }

            # Read the canonical name from port.json (includes .zip)
            CANONICAL_NAME=$(jq -r '.name' "$PORT_JSON")
            [[ "$CANONICAL_NAME" == "null" ]] && { echo "name missing in port.json"; continue; }

            # ZIP the staging directory
            ZIP_PATH="$ZIP_DIR/${CANONICAL_NAME}"
            echo "  Zipping → $ZIP_PATH"
            (cd "$STAGING_DIR" && zip -r -q "$ZIP_PATH" .) || continue

            # Screenshot & README from port dir
            SCREENSHOT=$(find "$PORT_DIR" -maxdepth 1 \( -iname "screenshot*.png" -o -iname "screenshot*.jpg" -o -iname "screenshot*.jpeg" \) | head -n1)
            [[ -f "$SCREENSHOT" ]] || { echo "No screenshot"; continue; }

            README=$(find "$PORT_DIR" -maxdepth 1 \( -iname "README.md" -o -iname "readme.md" \) | head -n1 || echo "")

            # Hash / size
            MD5=$(md5sum "$ZIP_PATH" | awk '{print $1}')
            SIZE=$(stat -c %s "$ZIP_PATH")
            DATE_UPDATED=$(date -u +"%Y-%m-%dT%H:%M")

            # URLs
            SCREENSHOT_URL="https://raw.githubusercontent.com/${GITHUB_REPOSITORY}/main/${SCREENSHOT#"$GITHUB_WORKSPACE/"}"
            README_URL=""
            [[ -n "$README" ]] && README_URL="https://raw.githubusercontent.com/${GITHUB_REPOSITORY}/main/${README#"$GITHUB_WORKSPACE/"}"
            DOWNLOAD_URL="https://github.com/${GITHUB_REPOSITORY}/releases/download/ports-latest/${CANONICAL_NAME}"

            # Load full original JSON
            ORIGINAL_JSON=$(cat "$PORT_JSON")

            # Check if entry already exists (match by canonical name)
            EXISTING_ENTRY=$(jq -c --arg name "$CANONICAL_NAME" '.[] | select(.name == $name)' "$PORTS_JSON" 2>/dev/null || echo "")

            if [[ -n "$EXISTING_ENTRY" ]]; then
              OLD_MD5=$(echo "$EXISTING_ENTRY" | jq -r '.source.md5 // empty')
              OLD_SIZE=$(echo "$EXISTING_ENTRY" | jq -r '.source.size // empty')
              if [[ "$MD5" == "$OLD_MD5" && "$SIZE" == "$OLD_SIZE" ]]; then
                DATE_UPDATED=$(echo "$EXISTING_ENTRY" | jq -r '.source.date_updated')
              fi
            fi

            # Merge: preserve full original (including name), only update source
            PORT_JSON_MERGED=$(jq -n \
              --argjson original "$ORIGINAL_JSON" \
              --arg date_updated "$DATE_UPDATED" \
              --arg download_url "$DOWNLOAD_URL" \
              --arg readme_url "$README_URL" \
              --arg screenshot_url "$SCREENSHOT_URL" \
              --arg size "$SIZE" \
              --arg md5 "$MD5" \
              '$original + {source: {date_updated: $date_updated, download_url: $download_url, screenshot_url: $screenshot_url, readme_url: $readme_url, size: ($size|tonumber), md5: $md5}}'
            )

            # Replace entry in ports.json using canonical name
            TMP=$(mktemp)
            jq --arg name "$CANONICAL_NAME" --argjson portjson "$PORT_JSON_MERGED" \
              'map(select(.name != $name)) + [$portjson]' \
              "$PORTS_JSON" > "$TMP" && mv "$TMP" "$PORTS_JSON"

            echo "Updated $CANONICAL_NAME in ports.json"
          done
          
      # ────────────────────── SYNC DISK, JSON, AND RELEASE ──────────────────────
      - name: Purge deleted or invalid ports
        env:
          GITHUB_TOKEN: ${{ secrets.TOKEN }}
        run: |
          set -euo pipefail
          PORTS_JSON="$GITHUB_WORKSPACE/docs/ports.json"

          echo "Validating ports on disk..."

          # Collect canonical names from disk
          VALID_NAMES=()
          while IFS= read -r json_file; do
            dir="$(dirname "$json_file")"

            SCREENSHOT=$(find "$dir" -maxdepth 1 \
              \( -iname "screenshot*.png" -o -iname "screenshot*.jpg" -o -iname "screenshot*.jpeg" \) \
              | head -n1)

            [[ -n "$SCREENSHOT" ]] || {
              echo "Skipping invalid port (no screenshot): $dir"
              continue
            }

            NAME=$(jq -r '.name // empty' "$json_file")
            [[ -n "$NAME" ]] && VALID_NAMES+=("$NAME")
          done < <(find ports/released -type f -name 'port.json')

          # Nothing valid on disk → hard stop
          [[ "${#VALID_NAMES[@]}" -gt 0 ]] || {
            echo "No valid ports found on disk; refusing to purge"
            exit 0
          }

          # Prune ports.json (keep only disk-backed ports)
          VALID_NAMES_JSON=$(printf '%s\n' "${VALID_NAMES[@]}" | jq -R . | jq -s .)

          TMP=$(mktemp)
          jq --argjson valid "$VALID_NAMES_JSON" \
            'map(select(.name as $n | $valid | index($n)))' \
            "$PORTS_JSON" > "$TMP" && mv "$TMP" "$PORTS_JSON"

          echo "ports.json synced (Valid ports: ${#VALID_NAMES[@]})"

          # Prune release assets (mirror ports.json logic)
          RELEASE_ID=$(gh api repos/${GITHUB_REPOSITORY}/releases/tags/ports-latest \
            --jq '.id' 2>/dev/null || true)

          [[ -n "$RELEASE_ID" ]] || exit 0

          mapfile -t ASSETS < <(
            gh api repos/${GITHUB_REPOSITORY}/releases/$RELEASE_ID/assets \
              --jq '.[] | "\(.name):\(.id)"'
          )

          for asset in "${ASSETS[@]}"; do
            ASSET_NAME="${asset%%:*}"
            ASSET_ID="${asset#*:}"

            [[ "$ASSET_NAME" == *.zip ]] || continue

            if ! printf '%s\n' "${VALID_NAMES[@]}" | grep -qx "$ASSET_NAME"; then
              echo "Deleting orphaned asset: $ASSET_NAME"
              gh api -X DELETE "repos/${GITHUB_REPOSITORY}/releases/assets/$ASSET_ID" || true
            fi
          done

      # ────────────────────── SORT ──────────────────────
      - name: Sort ports by title
        run: |
          jq 'sort_by(.attr.title // "Untitled")' "$GITHUB_WORKSPACE/docs/ports.json" \
            > "$GITHUB_WORKSPACE/docs/ports.tmp" && \
          mv "$GITHUB_WORKSPACE/docs/ports.tmp" "$GITHUB_WORKSPACE/docs/ports.json"

      # ────────────────────── RELEASE ──────────────────────
      - name: Ensure release exists
        if: ${{ steps.ports.outputs.ports != '' }}
        env:
          GH_TOKEN: ${{ secrets.TOKEN }}
        run: |
          gh release view ports-latest --json id &>/dev/null || \
            gh release create ports-latest --title "Ports" --notes "Automated release" --target ${{ github.sha }}

      - name: Delete conflicting release assets
        if: ${{ steps.ports.outputs.ports != '' }}
        env:
          GITHUB_TOKEN: ${{ secrets.TOKEN }}
        run: |
          RELEASE_ID=$(gh api repos/${GITHUB_REPOSITORY}/releases/tags/ports-latest --jq '.id' || echo "")
          [ -z "$RELEASE_ID" ] && { echo "No release found, skipping asset deletion"; exit 0; }
          for FILE in temp_ports/*.zip; do
            NAME=$(basename "$FILE")
            ASSET_ID=$(gh api repos/${GITHUB_REPOSITORY}/releases/$RELEASE_ID/assets --jq ".[] | select(.name==\"$NAME\") | .id" 2>/dev/null || echo "")
            if [ -n "$ASSET_ID" ]; then
              echo "Deleting old asset: $NAME ($ASSET_ID)"
              gh api -X DELETE "repos/${GITHUB_REPOSITORY}/releases/assets/$ASSET_ID" || true
              sleep 3
            fi
          done

      - name: Upload zips with retries
        if: ${{ steps.ports.outputs.ports != '' }}
        env:
          GITHUB_TOKEN: ${{ secrets.TOKEN }}
        run: |
          MAX_RETRIES=3
          for FILE in temp_ports/*.zip; do
            NAME=$(basename "$FILE")
            ATTEMPT=1
            until [ $ATTEMPT -gt $MAX_RETRIES ]; do
              echo "Uploading $NAME (attempt $ATTEMPT)..."
              gh release upload ports-latest "$FILE" --clobber && break
              echo "Failed to upload $NAME, retrying in 5s..."
              sleep 5
              ATTEMPT=$((ATTEMPT+1))
            done
          done

      - name: Commit ports.json
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add docs/ports.json
          if ! git diff --cached --quiet; then
            git commit -m "Update ports.json"
            git push
          fi